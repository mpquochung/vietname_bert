{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from Trainer.head_trainer import Trainer\n",
    "from utils.dataloader import CreateDataset\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score,f1_score, recall_score, precision_score, confusion_matrix\n",
    "import numpy as np\n",
    "from architecture.simplebert import BertLinear1HEAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = pd.read_table('dataset/Test/localch.tsv')\n",
    "test_set.drop(columns=['Unnamed: 2',\"Unnamed: 3\",\"Unnamed: 4\"], inplace=True)\n",
    "test_set.columns = ['text','label_x']\n",
    "batch_size = 128\n",
    "bert_name=\"FacebookAI/xlm-roberta-base\"\n",
    "test_data_loader  = CreateDataset(test_set['text'], test_set['label_x'], bert_name, batch_size=batch_size).todataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = pd.read_table('dataset/Test/Table-S6-career-2019.tsv')\n",
    "test_set = test_set.iloc[:, :2]\n",
    "test_set.columns = ['text','label_x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predict:\n",
    "    def __init__(self,name, test_data_loader,model_path):\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.bertcnn=BertLinear1HEAD(name).to(self.device)\n",
    "        self.bertcnn.load_state_dict(torch.load(model_path))  # Load the state dictionary\n",
    "        self.bertcnn.eval()\n",
    "\n",
    "\n",
    "        self.test_data_loader  = test_data_loader\n",
    "        \n",
    "        \n",
    "    \n",
    "    def predictions_labels(self,preds,labels):\n",
    "        pred = np.argmax(preds,axis=1).flatten()\n",
    "        label = labels.flatten()\n",
    "        return pred,label\n",
    "    \n",
    "    def eval(self):\n",
    "        all_true_sent = []\n",
    "        all_pred_sent = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(self.test_data_loader):\n",
    "                b_input_ids = batch[0].to(self.device)\n",
    "                b_input_mask = batch[1].to(self.device)\n",
    "                b_sent = batch[2].to(self.device)\n",
    "                #b_clas = batch[3].to(self.device)\n",
    "\n",
    "                self.sent_predictions = self.bertcnn(b_input_ids,b_input_mask)\n",
    "                #loss1 = self.criterion(sent_predictions, b_sent) \n",
    "                #loss2 = self.criterion(clas_predictions, b_clas) \n",
    "\n",
    "                #t_loss = loss1\n",
    "\n",
    "                self.sent_predictions = self.sent_predictions.detach().cpu().numpy()\n",
    "                #clas_predictions = clas_predictions.detach().cpu().numpy()\n",
    "\n",
    "                label_sent = b_sent.to('cpu').numpy()\n",
    "                #label_clas = b_clas.to('cpu').numpy()\n",
    "\n",
    "                pred1, true1 = self.predictions_labels(self.sent_predictions,label_sent)\n",
    "                #pred2, true2 = self.predictions_labels(clas_predictions,label_clas)\n",
    "\n",
    "                all_pred_sent.extend(pred1)\n",
    "                #all_pred_clas.extend(pred2)\n",
    "\n",
    "                all_true_sent.extend(true1)\n",
    "                #all_true_clas.extend(true2)\n",
    "\n",
    "            val_accuracy_sent = accuracy_score(all_pred_sent,all_true_sent)\n",
    "            #val_accuracy_clas = accuracy_score(all_pred_clas,all_true_clas)\n",
    "\n",
    "            sent_f1_score = f1_score(all_pred_sent,all_true_sent,average='macro')\n",
    "            sent_f1_scorew = f1_score(all_pred_sent,all_true_sent,average='weighted')\n",
    "            #clas_f1_score = f1_score(all_pred_clas,all_true_clas,average='macro')\n",
    "            #clas_f1_scorew = f1_score(all_pred_clas,all_true_clas,average='weighted')\n",
    "            precision_score_sent = precision_score(all_pred_sent,all_true_sent) \n",
    "            recall_score_sent = recall_score(all_pred_sent,all_true_sent)\n",
    "            accs = (val_accuracy_sent)\n",
    "            f1s= (sent_f1_score,sent_f1_scorew)\n",
    "        return  accs,  f1s, precision_score_sent, recall_score_sent\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/1027 [00:20<1:29:14,  5.23s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m predicting \u001b[38;5;241m=\u001b[39m Predict(bert_name, test_data_loader, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel/Epoch-5-2-head-linear-smart-10_0-redo.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mpredicting\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[23], line 36\u001b[0m, in \u001b[0;36mPredict.eval\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     30\u001b[0m sent_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbertcnn(b_input_ids,b_input_mask)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m#loss1 = self.criterion(sent_predictions, b_sent) \u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m#loss2 = self.criterion(clas_predictions, b_clas) \u001b[39;00m\n\u001b[0;32m     33\u001b[0m \n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m#t_loss = loss1\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m sent_predictions \u001b[38;5;241m=\u001b[39m \u001b[43msent_predictions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m#clas_predictions = clas_predictions.detach().cpu().numpy()\u001b[39;00m\n\u001b[0;32m     39\u001b[0m label_sent \u001b[38;5;241m=\u001b[39m b_sent\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "predicting = Predict(bert_name, test_data_loader, \"model/Epoch-5-2-head-linear-smart-10_0-redo.pt\")\n",
    "res = predicting.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = test_set[test_set['label_x'] == 1]\n",
    "df.to_excel('dataset/Test/table-s6-career-2019-1.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
